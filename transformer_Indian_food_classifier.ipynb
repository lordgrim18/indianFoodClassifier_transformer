{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Hetzba9AVFm"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import notebook_login\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from datasets import load_metric\n",
        "from transformers import ViTFeatureExtractor\n",
        "from transformers import ViTForImageClassification\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "\n",
        "import torch\n",
        "from torchvision.transforms import (\n",
        "    CenterCrop,\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomResizedCrop,\n",
        "    Resize,\n",
        "    ToTensor,\n",
        ")"
      ],
      "metadata": {
        "id": "5okZ0hyeoixO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "NLy3f5HnpS_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo apt -qq install git-lfs\n",
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "K0FCJhbopVA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4q1D6aknqmun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/food.zip\" -d /tmp/foodimg"
      ],
      "metadata": {
        "id": "1a1k6tVUsFe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"imagefolder\", data_dir=\"/tmp/foodimg\")\n",
        "ds = ds['train']"
      ],
      "metadata": {
        "id": "MjfnozuesFc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = ds.train_test_split(test_size=0.10)"
      ],
      "metadata": {
        "id": "3qKo8u5hsFYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "1rSjEOEnsFUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pushing data to Huggingface public hub"
      ],
      "metadata": {
        "id": "q6-ycps2tgRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.push_to_hub(\"lordgrim18/indian_food_images\")"
      ],
      "metadata": {
        "id": "bhN-M3gasFR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Accessing the dataset from the public hub"
      ],
      "metadata": {
        "id": "lY6aijtxtol6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"lordgrim18/indian_food_images\")"
      ],
      "metadata": {
        "id": "wttBGgiKsFPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex = data['train'][400]\n",
        "ex"
      ],
      "metadata": {
        "id": "rmagyDepsFMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = ex['image']\n",
        "image"
      ],
      "metadata": {
        "id": "eJE-VrijsFJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = data['train'].features['label']\n",
        "labels"
      ],
      "metadata": {
        "id": "C1hbYPEFsFFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.int2str(ex['label'])"
      ],
      "metadata": {
        "id": "wgO8qjN1sFCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"accuracy\")"
      ],
      "metadata": {
        "id": "3uLYUvdGsFAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "_iv77ojYsE9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = data[\"train\"].features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label"
      ],
      "metadata": {
        "id": "j_eW8fNCsE68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)"
      ],
      "metadata": {
        "id": "-i9-a5nzsE4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
        "train_transforms = Compose(\n",
        "        [\n",
        "            RandomResizedCrop(feature_extractor.size),\n",
        "            RandomHorizontalFlip(),\n",
        "            ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    )\n",
        "val_transforms = Compose(\n",
        "        [\n",
        "            RandomResizedCrop(feature_extractor.size),\n",
        "            #CenterCrop(feature_extractor.size),\n",
        "            ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "GyFOD86HsE1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_train(example_batch):\n",
        "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [\n",
        "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
        "    ]\n",
        "    return example_batch"
      ],
      "metadata": {
        "id": "KEIQIrr3sEwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_val(example_batch):\n",
        "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
        "    return example_batch"
      ],
      "metadata": {
        "id": "YmebC_COsDX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split up training into training + validation\n",
        "train_ds = data['train']\n",
        "val_ds = data['test']"
      ],
      "metadata": {
        "id": "vuFafMKNxB2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.set_transform(preprocess_train)\n",
        "val_ds.set_transform(preprocess_val)"
      ],
      "metadata": {
        "id": "wIKANii8xBzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[1]"
      ],
      "metadata": {
        "id": "tjb01m5SxBxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name_or_path, \n",
        "    num_labels=len(labels),\n",
        "    id2label={str(i): c for i, c in enumerate(labels)},\n",
        "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
        ")"
      ],
      "metadata": {
        "id": "CJk2rzAQxBu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    'finetuned-indian-food',\n",
        "  per_device_train_batch_size=16,\n",
        "  evaluation_strategy=\"steps\",\n",
        "  num_train_epochs=4,\n",
        "  fp16=True,\n",
        "  save_steps=100,\n",
        "  eval_steps=100,\n",
        "  logging_steps=10,\n",
        "  learning_rate=2e-4,\n",
        "  save_total_limit=2,\n",
        "  remove_unused_columns=False,\n",
        "  push_to_hub=True,\n",
        "  report_to='tensorboard',\n",
        "  load_best_model_at_end=True,\n",
        "  hub_strategy=\"end\"\n",
        ")"
      ],
      "metadata": {
        "id": "h6TwPBGzxBsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
      ],
      "metadata": {
        "id": "dXu_ZFm7xBit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
        "        'labels': torch.tensor([x['label'] for x in batch])\n",
        "    }"
      ],
      "metadata": {
        "id": "ldaQZInSxqdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=feature_extractor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        ")"
      ],
      "metadata": {
        "id": "Dc56pD6nxy1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = trainer.train()"
      ],
      "metadata": {
        "id": "moM94ZR3xyyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "Z43NGoHlxywN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate()\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "id": "hfAzHrATxytb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##uploading into the hub"
      ],
      "metadata": {
        "id": "-SnLTApzyH46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"finetuned_from\": model.config._name_or_path,\n",
        "    \"tasks\": \"image-classification\",\n",
        "    \"dataset\": 'indian_food_images',\n",
        "    \"tags\": ['image-classification'],\n",
        "}\n",
        "\n",
        "if training_args.push_to_hub:\n",
        "    trainer.push_to_hub('üçª cheers', **kwargs)\n",
        "else:\n",
        "    trainer.create_model_card(**kwargs)"
      ],
      "metadata": {
        "id": "-VnxIXxMxyqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##testing the model by loading a single image"
      ],
      "metadata": {
        "id": "rZi1dV89yUhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoModelForImageClassification, AutoFeatureExtractor\n",
        "import torch"
      ],
      "metadata": {
        "id": "tcviDaHxxynq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://cdn.pixabay.com/photo/2016/10/25/13/42/indian-1768906_960_720.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "image"
      ],
      "metadata": {
        "id": "gx6KAog0xyiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_name = \"lordgrim18/finetuned-indian-food\"\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(repo_name)\n",
        "model = AutoModelForImageClassification.from_pretrained(repo_name)"
      ],
      "metadata": {
        "id": "ug10aVZkybxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare image for the model\n",
        "encoding = feature_extractor(image.convert(\"RGB\"), return_tensors=\"pt\")\n",
        "print(encoding.pixel_values.shape)"
      ],
      "metadata": {
        "id": "cSDbDfsx0Fo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "with torch.no_grad():\n",
        "  outputs = model(**encoding)\n",
        "  logits = outputs.logits"
      ],
      "metadata": {
        "id": "q8iusu440FiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "id": "5uVpYm8C0Ffo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pipeline\n",
        "##we can also use pipeline to quickly access our model"
      ],
      "metadata": {
        "id": "16s3S6sF0rAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "QrSBVZkU0Fb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"image-classification\", \"lordgrim18/finetuned-indian-food\")"
      ],
      "metadata": {
        "id": "ofqttX8w0FY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://cdn.pixabay.com/photo/2016/10/25/13/42/indian-1768906_960_720.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "pipe(image)"
      ],
      "metadata": {
        "id": "NbMiXFQB0FV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"image-classification\", \n",
        "                model=model,\n",
        "                feature_extractor=feature_extractor)"
      ],
      "metadata": {
        "id": "8gULfU6Z1E-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(image)"
      ],
      "metadata": {
        "id": "wNu7pfj41E77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}